# Copyright 2024 SambaNova Systems, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

defaults:
    - nlp_default_args
    - _self_

hydra:
  searchpath: 
    - pkg://sambanova_modelzoo/libs/nlp/args

# Model configs, changes here are effective only if the PEF is compiled/re-compiled.
model:
    # Toggle to control the normalization layer precision. True means fp32 and false means bf16.
    fp32_ln: False
    # When this flag is True, logits are returned in fp32 precision. 
    # When this flag is False, logits are returned  bf16 precision. 
    fp32_logits: True
    # In LLMs, when there are multiple hidden layers, each layer hidden state is accumulated together. 
    # This flag controls whether the accumulation occurs in fp32 or bf16.
    fp32_skip_add: True
    # When this flag is False, the attention layer is performed in bf16. 
    # When this flag is True, the attention layer uses both fp32 and bf16 precision. 
    # See https://docs.sambanova.ai/developer/latest/mixed-precision.html
    mixedp_attn: True
    # The max number of tokens that the RDU graph can generate minus the input length.
    # The sequence length includes the input prompts and the generated tokens. 
    # At runtime, the length of input prompts must be smaller than max sequence length.
    max_seq_length: 4096

checkpoint:
    # Path to the downloaded Hugging Face cache, including checkpoints, model config and tokenizer.
    model_name_or_path: null

# A string of either compile or run.
command: null

# Compiler configs for PEF optimization and generation.
# Changes here will only be reflected if the PEF is compiled/re-compiled.
# NOTE: only need to change arch/output_folder and keep the others as default.
samba_compile:
    # Required! Target RDU architecture to compile to: sn20, sn30, sn40. 
    arch: null
    # Output folder for the PEF and other artifacts. If null, defaults to the current working directory. 
    output_folder: null
    # The name of PEF file. If unspecified, we generate a name that's based on the app, PID, and current time. 
    pef_name: null
    # Optimization level, o1 fuses adjacent operators for better performance. 
    # The default O3 uses the full graph optimization scope and compiles more slowly.
    # See https://docs.sambanova.ai/developer/latest/compiler-o1.html for background information. 
    optim_level: o1
    # Whether to compile inference graph only. It should be always True for text generaton tasks.
    inference: True
    # A legacy flag for O1 optimization.
    o1_experimental_opts: True
    # An optional path to an operator fusion rules file that specifies the o1 pattern fusion 
    # and heuristis in predefined yaml file format. 
    # See https://docs.sambanova.ai/developer/latest/opfusion-rule-syntax.html
    optimization_rules: null
    # Fuse and map operator subgraphs using predefined o1 default patterns for better hardware utilization
    use_o1_default_rules: True

# Generation runtime configs
samba_run:
    # The path to the compiled PEF file.
    pef: null

# Application runtime configs
generation:
    # The batch size to compile a static graph. If you change this parameter you have to recompile. 
    batch_size: 1
    # Preset prompt text. The compiler expects that the number of prompts matches the batch_size that is specified
    # in the model configuration.
    prompts:
        - 'Once upon a time'
    # Maximum tokens to be generated. By default (max_seq_length - prompt_length) tokens.
    max_new_tokens: 32
    # Random seed for torch, numpy and python library
    seed: 12345
    output_dir: 'text_gen_telemetry'
